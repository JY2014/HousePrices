{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting House Prices using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "x_train = np.loadtxt('data/x_train_cleaned.txt', delimiter=',')\n",
    "x_test = np.loadtxt('data/x_test_cleaned.txt', delimiter=',')\n",
    "y_train_log = np.loadtxt('data/y_train_log.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# formatting for xgb\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train_log)\n",
    "dtest = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set initial parameters\n",
    "xgb1 = xgb.XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " nthread = 4,\n",
    " seed=0)\n",
    "\n",
    "xgb_param = xgb1.get_xgb_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set a large learning rate and tune n_estimators \n",
    "using the default learning rate of 0.2 to tune the other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model requires 391 estimators.\n",
      "The rmse is  0.1203396\n"
     ]
    }
   ],
   "source": [
    "# use 5-fold CV\n",
    "cv_folds = 5\n",
    "# stop when perfomance does not improve for 50 rounds\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "# tune number of trees\n",
    "cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=xgb_param['n_estimators'], nfold=cv_folds,\n",
    "    metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "print \"The model requires {} estimators.\". format(cvresult.shape[0])\n",
    "# update the parameter\n",
    "n_estimators = cvresult.shape[0]\n",
    "xgb_param['n_estimators'] = n_estimators\n",
    "# performance\n",
    "print \"The rmse is \", cvresult['test-rmse-mean'][n_estimators-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc2e27f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAFICAYAAADkqwLiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsIIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc0ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add a figure of the RMSE change over n_estimators\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(range(n_estimators), cvresult['test-rmse-mean'].values, label = \"Test\")\n",
    "ax1.plot(range(n_estimators), cvresult['train-rmse-mean'].values, label = \"Train\")\n",
    "\n",
    "ax1.set_ylim([0, 2])\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function to tune two parameters of XGBoost\n",
    "## Input: name and choices of the two parameters, the model and training data\n",
    "## Output: best score and the two parameters\n",
    "def two_param_tuning (param_name_1, list_1, param_name_2, list_2, xgb_param, dtrain):\n",
    "    best_score = 10e4\n",
    "    best_param_1 = -1\n",
    "    best_param_2 = -1\n",
    "\n",
    "    for param_1 in list_1:\n",
    "        xgb_param[param_name_1] = param_1\n",
    "        \n",
    "        for param_2 in list_2:\n",
    "            xgb_param[param_name_2] = param_2\n",
    "\n",
    "            cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=xgb_param['n_estimators'], nfold=cv_folds,\n",
    "                              metrics='rmse')\n",
    "            score = cvresult['test-rmse-mean'][xgb_param['n_estimators']-1]\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_param_1 = param_1\n",
    "                best_param_2 = param_2\n",
    "    \n",
    "    return best_score, best_param_1, best_param_2\n",
    "\n",
    "\n",
    "### Function to tune one parameter of XGBoost\n",
    "## Input: name and choices of the parameter, the model and training data\n",
    "## Output: best score and the parameter\n",
    "def one_param_tuning (param_name_1, list_1, xgb_param, dtrain):\n",
    "    best_score = 10e4\n",
    "    best_param_1 = -1\n",
    "\n",
    "    for param_1 in list_1:\n",
    "        xgb_param[param_name_1] = param_1\n",
    "\n",
    "        cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=xgb_param['n_estimators'], nfold=cv_folds,\n",
    "                          metrics='rmse')\n",
    "        score = cvresult['test-rmse-mean'][xgb_param['n_estimators']-1]\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_param_1 = param_1\n",
    "    \n",
    "    return best_score, best_param_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tune max_depth and min_child_weight\n",
    "Preventing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best max_depth is  3\n",
      "The best min_child_weight is  1\n",
      "The rmse is  0.1203396\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "max_depth_list = range(3, 10, 2)\n",
    "min_child_weight_list = range(1, 6, 2)\n",
    "\n",
    "best_score, best_max_depth, best_min_child_weight = two_param_tuning('max_depth', max_depth_list, \n",
    "                                                                     'min_child_weight', min_child_weight_list,\n",
    "                                                                     xgb_param, dtrain)\n",
    "\n",
    "print \"The best max_depth is \", best_max_depth\n",
    "print \"The best min_child_weight is \", best_min_child_weight\n",
    "print \"The rmse is \", best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning around the selected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best max_depth is  3\n",
      "The best min_child_weight is  1\n",
      "The rmse is  0.1203396\n"
     ]
    }
   ],
   "source": [
    "# fine tune around the best parameter values\n",
    "max_depth_list = range(2, 5, 1)\n",
    "min_child_weight_list = range(1, 4, 1)\n",
    "\n",
    "best_score, best_max_depth, best_min_child_weight = two_param_tuning('max_depth', max_depth_list, \n",
    "                                                                     'min_child_weight', min_child_weight_list,\n",
    "                                                                     xgb_param, dtrain)\n",
    "\n",
    "print \"The best max_depth is \", best_max_depth\n",
    "print \"The best min_child_weight is \", best_min_child_weight\n",
    "print \"The rmse is \", best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the parameters\n",
    "xgb_param['max_depth'] = best_max_depth\n",
    "xgb_param['min_child_weight'] = best_min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tune gamma\n",
    "related to loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best gamma is  0.0\n",
      "The rmse is  0.1203396\n"
     ]
    }
   ],
   "source": [
    "gamma_list = [i/100.0 for i in range(0,5)]\n",
    "\n",
    "best_score, best_gamma = one_param_tuning('gamma', gamma_list, xgb_param, dtrain)\n",
    "\n",
    "print \"The best gamma is \", best_gamma\n",
    "print \"The rmse is \", best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the parameter\n",
    "xgb_param['gamma'] = best_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best subsample is  0.8\n",
      "The best colsample_bytree is  0.8\n",
      "The rmse is  0.1203396\n"
     ]
    }
   ],
   "source": [
    "subsample_list = [i/10.0 for i in range(6,10)]\n",
    "colsample_bytree_list = [i/10.0 for i in range(6,10)]\n",
    "\n",
    "best_score, best_subsample, best_colsample_bytree = two_param_tuning('subsample', subsample_list, 'colsample_bytree', colsample_bytree_list,\n",
    "                                              xgb_param, dtrain)\n",
    "\n",
    "print \"The best subsample is \", best_subsample\n",
    "print \"The best colsample_bytree is \", best_colsample_bytree\n",
    "print \"The rmse is \", best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the parameters\n",
    "xgb_param['subsample'] = best_subsample\n",
    "xgb_param['colsample_bytree'] = best_colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fine tuning\n",
    "Using small learning rate and large number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model requires 2427 estimators.\n",
      "The rmse is  0.1188416\n"
     ]
    }
   ],
   "source": [
    "xgb_param['learning_rate'] = 0.01\n",
    "xgb_param['n_estimators'] = 5000\n",
    "\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=xgb_param['n_estimators'], nfold=cv_folds,\n",
    "    metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "print \"The model requires {} estimators.\". format(cvresult.shape[0])\n",
    "# update the parameter\n",
    "n_estimators = cvresult.shape[0]\n",
    "xgb_param['n_estimators'] = n_estimators\n",
    "# performance\n",
    "print \"The rmse is \", cvresult['test-rmse-mean'][n_estimators-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0.0,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 2427,\n",
       " 'nthread': 4,\n",
       " 'objective': 'reg:linear',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 0,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final parameters\n",
    "xgb_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the final model\n",
    "xgb1 = xgb.XGBRegressor(\n",
    " learning_rate = 0.01,\n",
    " n_estimators = 2427,\n",
    " subsample = 0.8,\n",
    " colsample_bytree = 0.8,\n",
    " objective= 'reg:linear',\n",
    " max_depth = 3,\n",
    " min_child_weight = 1,\n",
    " nthread = 4,\n",
    " seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=2427, nthread=4,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "xgb1.fit(x_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred = xgb1.predict(x_test)\n",
    "\n",
    "# convert to original scale and save\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['SalePrice'] = np.exp(y_pred)\n",
    "submission.to_csv('results/xgb.csv', sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Predict on training data using k-fold for ensemble purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_2 = cross_val_predict(xgb1, x_train, y_train_log, cv = 5)\n",
    "\n",
    "# remember to convert to original scale\n",
    "xgb_train = pd.DataFrame(np.exp(y_pred_2))\n",
    "xgb_train.to_csv('results/xgb_train.csv', sep = ',', index=False, header = None)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
